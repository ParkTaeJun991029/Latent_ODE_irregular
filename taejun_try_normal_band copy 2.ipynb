{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import umap\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import SystemRandom\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "import torch.optim as optim\n",
    "\n",
    "import lib.utils as utils\n",
    "from lib.plotting import *\n",
    "\n",
    "from lib.rnn_baselines import *\n",
    "from lib.ode_rnn import *\n",
    "from lib.create_latent_ode_model import create_LatentODE_model\n",
    "from lib.parse_datasets import parse_datasets\n",
    "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
    "from lib.diffeq_solver import DiffeqSolver\n",
    "from mujoco_physics import HopperPhysics\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import lib.utils as utils\n",
    "from lib.diffeq_solver import DiffeqSolver\n",
    "from generate_timeseries import Periodic_1d\n",
    "from torch.distributions import uniform\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from mujoco_physics import HopperPhysics\n",
    "from physionet import variable_time_collate_fn, get_data_min_max\n",
    "from person_activity import PersonActivity, variable_time_collate_fn_activity\n",
    "\n",
    "from sklearn import model_selection\n",
    "import random\n",
    "from lib.utils import compute_loss_all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative model for noisy data based on ODE\n",
    "parser = argparse.ArgumentParser('Latent ODE')\n",
    "parser.add_argument('-n',  type=int, default=10000, help=\"Size of the dataset\")\n",
    "parser.add_argument('--niters', type=int, default=20)\n",
    "parser.add_argument('--lr',  type=float, default=1e-2, help=\"Starting learning rate.\")\n",
    "parser.add_argument('-b', '--batch-size', type=int, default=256)\n",
    "parser.add_argument('--viz', action='store_true', default=False, help=\"Show plots while training\")\n",
    "\n",
    "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
    "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
    "parser.add_argument('-r', '--random-seed', type=int, default=1991, help=\"Random_seed\")\n",
    "\n",
    "parser.add_argument('--dataset', type=str, default='physionet', help=\"Dataset to load. Available: physionet, activity, hopper, periodic\")\n",
    "parser.add_argument('-s', '--sample-tp', type=float, default=None, help=\"Number of time points to sub-sample.\"\n",
    "\t\"If > 1, subsample exact number of points. If the number is in [0,1], take a percentage of available points per time series. If None, do not subsample\")\n",
    "\n",
    "parser.add_argument('-c', '--cut-tp', type=int, default=None, help=\"Cut out the section of the timeline of the specified length (in number of points).\"\n",
    "\t\"Used for periodic function demo.\")\n",
    "\n",
    "parser.add_argument('--quantization', type=float, default=5, help=\"Quantization on the physionet dataset.\"\n",
    "\t\"Value 1 means quantization by 1 hour, value 0.1 means quantization by 0.1 hour = 6 min\")\n",
    "\n",
    "parser.add_argument('--latent-ode', action='store_true', default=True,  help=\"Run Latent ODE seq2seq model\")\n",
    "parser.add_argument('--z0-encoder', type=str, default='odernn', help=\"Type of encoder for Latent ODE model: odernn or rnn\")\n",
    "\n",
    "parser.add_argument('--classic-rnn', action='store_true', help=\"Run RNN baseline: classic RNN that sees true points at every point. Used for interpolation only.\")\n",
    "parser.add_argument('--rnn-cell', default=\"gru\", help=\"RNN Cell type. Available: gru (default), expdecay\")\n",
    "parser.add_argument('--input-decay', action='store_true', help=\"For RNN: use the input that is the weighted average of impirical mean and previous value (like in GRU-D)\")\n",
    "\n",
    "parser.add_argument('--ode-rnn', action='store_true', help=\"Run ODE-RNN baseline: RNN-style that sees true points at every point. Used for interpolation only.\")\n",
    "\n",
    "parser.add_argument('--rnn-vae', action='store_true', help=\"Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss.\")\n",
    "\n",
    "parser.add_argument('-l', '--latents', type=int, default=6, help=\"Size of the latent state\")\n",
    "parser.add_argument('--rec-dims', type=int, default=40, help=\"Dimensionality of the recognition model (ODE or RNN).\")\n",
    "\n",
    "parser.add_argument('--rec-layers', type=int, default=3, help=\"Number of layers in ODE func in recognition ODE\")\n",
    "parser.add_argument('--gen-layers', type=int, default=3, help=\"Number of layers in ODE func in generative ODE\")\n",
    "\n",
    "parser.add_argument('-u', '--units', type=int, default=50, help=\"Number of units per layer in ODE func\")\n",
    "parser.add_argument('-g', '--gru-units', type=int, default=100, help=\"Number of units per layer in each of GRU update networks\")\n",
    "\n",
    "parser.add_argument('--poisson', action='store_true', help=\"Model poisson-process likelihood for the density of events in addition to reconstruction.\")\n",
    "parser.add_argument('--classif', action='store_true', help=\"Include binary classification loss -- used for Physionet dataset for hospiral mortality\")\n",
    "\n",
    "parser.add_argument('--linear-classif', action='store_true', help=\"If using a classifier, use a linear classifier instead of 1-layer NN\")\n",
    "parser.add_argument('--extrap', action='store_true', help=\"Set extrapolation mode. If this flag is not set, run interpolation mode.\")\n",
    "\n",
    "parser.add_argument('-t', '--timepoints', type=int, default=100, help=\"Total number of time-points\")\n",
    "parser.add_argument('--max-t',  type=float, default=5., help=\"We subsample points in the interval [0, args.max_tp]\")\n",
    "parser.add_argument('--noise-weight', type=float, default=0.01, help=\"Noise amplitude for generated traejctories\")\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.batch_size = 16\n",
    "args.classif = False\n",
    "args.quantization = 5\n",
    "args.niters = 1000\n",
    "args.n = 24\n",
    "args.s =10\n",
    "args.l = 20\n",
    "args.rec_dims = 10\n",
    "args.rec_layers = 5\n",
    "args.gen_layers = 5\n",
    "args.latent_ode\n",
    "args.viz = True\n",
    "file_name = 'taejun_sim_'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=16, classic_rnn=False, classif=False, cut_tp=None, dataset='physionet', extrap=False, gen_layers=5, gru_units=100, input_decay=False, l=20, latent_ode=True, latents=6, linear_classif=False, load=None, lr=0.01, max_t=5.0, n=24, niters=1000, noise_weight=0.01, ode_rnn=False, poisson=False, quantization=5, random_seed=1991, rec_dims=10, rec_layers=5, rnn_cell='gru', rnn_vae=False, s=10, sample_tp=None, save='experiments/', timepoints=100, units=50, viz=True, z0_encoder='odernn')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from jdcal import jd2gcal\n",
    "from datetime import datetime\n",
    "\n",
    "class CustomClass(object):\n",
    "    params = ['Magnitude']  # Uncertainty_of_Magnitude 제외\n",
    "\n",
    "    params_dict = {k: i for i, k in enumerate(params)}\n",
    "\n",
    "    def __init__(self, root, train=True, preprocess=False,\n",
    "                 quantization=1, n_samples=None, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.quantization = quantization\n",
    "        self.device = device\n",
    "        self.reduce = \"average\"\n",
    "        if preprocess:\n",
    "            self.preprocess()\n",
    "\n",
    "        self.data = torch.load(os.path.join(self.root, 'lc_' + str(self.quantization) + '.pt'))\n",
    "        self.labels = torch.zeros(len(self.data))\n",
    "\n",
    "        if n_samples is not None:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.labels = self.labels[:n_samples]\n",
    "\n",
    "    def preprocess(self):\n",
    "        simulation_data_root = self.root \n",
    "        data_list = [f for f in os.listdir(simulation_data_root) if f.endswith('.txt')]\n",
    "        data_list.sort()\n",
    "        light_curves = []\n",
    "\n",
    "        for name in tqdm(data_list):\n",
    "            lc_name = name.partition('.')[0]\n",
    "            with open(os.path.join(simulation_data_root, name)) as f:\n",
    "                # next(f)  # 헤더 건너뛰기\n",
    "                magnitudes = [float(line.rstrip().split(' ')[1]) for line in f]\n",
    "                global_min = min(magnitudes)\n",
    "                global_max = max(magnitudes)\n",
    "\n",
    "            # 파일을 다시 열어서 데이터 처리\n",
    "            with open(os.path.join(simulation_data_root, name)) as f:\n",
    "                next(f)\n",
    "                lines = f.readlines()\n",
    "                prev_time = 0\n",
    "                tt = [0.]\n",
    "                vals = [torch.zeros(len(self.params), device=self.device)]\n",
    "                mask = [torch.zeros(len(self.params), device=self.device)]\n",
    "                for line in lines:\n",
    "                    time, magnitude = line.rstrip().split(' ')[:2]\n",
    "                    time = float(time)\n",
    "                    magnitude = float(magnitude)\n",
    "\n",
    "                    # 파일별 최소/최대값으로 스케일링\n",
    "                    scaled_magnitude = (magnitude - global_min) / (global_max - global_min) if global_max > global_min else 0.0\n",
    "\n",
    "                    if time != prev_time:\n",
    "                        tt.append(time)\n",
    "                        vals.append(torch.zeros(len(self.params), device=self.device))\n",
    "                        mask.append(torch.zeros(len(self.params), device=self.device))\n",
    "                        prev_time = time\n",
    "\n",
    "                    vals[-1][0] = scaled_magnitude  # 스케일된 값 사용\n",
    "                    mask[-1][0] = 1\n",
    "\n",
    "            tt = torch.tensor(tt, device=self.device)[1:]\n",
    "            vals = torch.stack(vals)[1:]\n",
    "            mask = torch.stack(mask)[1:]\n",
    "            labels = None\n",
    "            light_curves.append((lc_name, tt, vals, mask, labels))\n",
    "\n",
    "        torch.save(light_curves, os.path.join(self.root, 'lc_' + str(self.quantization) + '.pt'))\n",
    "        print('Done!')\n",
    "\n",
    "\n",
    "\n",
    "    # def preprocess(self):\n",
    "    #     simulation_data_root = self.root \n",
    "    #     data_list = [f for f in os.listdir(simulation_data_root) if f.endswith('.txt')]\n",
    "    #     data_list.sort()\n",
    "    #     light_curves = []\n",
    "\n",
    "    #     # 전체 데이터셋에 대한 최소값과 최대값을 초기화\n",
    "    #     global_min = float('inf')\n",
    "    #     global_max = float('-inf')\n",
    "\n",
    "    #     # 최소값과 최대값 찾기\n",
    "    #     for name in tqdm(data_list):\n",
    "    #         with open(os.path.join(simulation_data_root, name)) as f:\n",
    "    #             next(f)  # 헤더 건너뛰기\n",
    "    #             for line in f:\n",
    "    #                 _, magnitude = line.rstrip().split(' ')[:2]\n",
    "    #                 magnitude = float(magnitude)\n",
    "    #                 global_min = min(global_min, magnitude)\n",
    "    #                 global_max = max(global_max, magnitude)\n",
    "\n",
    "    #     # 데이터 스케일링 및 처리\n",
    "    #     for name in tqdm(data_list):\n",
    "    #         lc_name = name.partition('.')[0]\n",
    "    #         with open(os.path.join(simulation_data_root, name)) as f:\n",
    "    #             next(f)\n",
    "    #             lines = f.readlines()\n",
    "    #             prev_time = 0\n",
    "    #             tt = [0.]\n",
    "    #             vals = [torch.zeros(len(self.params), device=self.device)]\n",
    "    #             mask = [torch.zeros(len(self.params), device=self.device)]\n",
    "    #             for line in lines:\n",
    "    #                 time, magnitude = line.rstrip().split(' ')[:2]\n",
    "    #                 time = float(time)\n",
    "    #                 magnitude = float(magnitude)\n",
    "\n",
    "    #                 # 스케일링: (magnitude - global_min) / (global_max - global_min)\n",
    "    #                 scaled_magnitude = (magnitude - global_min) / (global_max - global_min)\n",
    "\n",
    "    #                 if time != prev_time:\n",
    "    #                     tt.append(time)\n",
    "    #                     vals.append(torch.zeros(len(self.params), device=self.device))\n",
    "    #                     mask.append(torch.zeros(len(self.params), device=self.device))\n",
    "    #                     prev_time = time\n",
    "\n",
    "    #                 vals[-1][0] = scaled_magnitude  # 스케일된 값 사용\n",
    "    #                 mask[-1][0] = 1\n",
    "\n",
    "    #         tt = torch.tensor(tt, device=self.device)[1:]\n",
    "    #         vals = torch.stack(vals)[1:]\n",
    "    #         mask = torch.stack(mask)[1:]\n",
    "    #         labels = None\n",
    "    #         light_curves.append((lc_name, tt, vals, mask, labels))\n",
    "\n",
    "    #     torch.save(light_curves, os.path.join(self.root, 'lc_' + str(self.quantization) + '.pt'))\n",
    "    #     print('Done!')\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Split: {}\\n'.format('train' if self.train else 'test')\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        fmt_str += '    Quantization: {}\\n'.format(self.quantization)\n",
    "        fmt_str += '    Reduce: {}\\n'.format(self.reduce)\n",
    "        return fmt_str\n",
    "\n",
    "    def visualize(self, timesteps, data, mask, plot_name):\n",
    "        width = 15\n",
    "        height = 15\n",
    "\n",
    "        non_zero_attributes = (torch.sum(mask,0) > 2).numpy()\n",
    "        non_zero_idx = [i for i in range(len(non_zero_attributes)) if non_zero_attributes[i] == 1.]\n",
    "        n_non_zero = sum(non_zero_attributes)\n",
    "\n",
    "        mask = mask[:, non_zero_idx]\n",
    "        data = data[:, non_zero_idx]\n",
    "\n",
    "        params_non_zero = [self.params[i] for i in non_zero_idx]\n",
    "        params_dict = {k: i for i, k in enumerate(params_non_zero)}\n",
    "\n",
    "        n_col = 3\n",
    "        n_row = n_non_zero // n_col + (n_non_zero % n_col > 0)\n",
    "        fig, ax_list = plt.subplots(n_row, n_col, figsize=(width, height), facecolor='white')\n",
    "\n",
    "        #for i in range(len(self.params)):\n",
    "        for i in range(n_non_zero):\n",
    "            param = params_non_zero[i]\n",
    "            param_id = params_dict[param]\n",
    "\n",
    "            tp_mask = mask[:,param_id].long()\n",
    "\n",
    "            tp_cur_param = timesteps[tp_mask == 1.]\n",
    "            data_cur_param = data[tp_mask == 1., param_id]\n",
    "\n",
    "            ax_list[i // n_col, i % n_col].plot(tp_cur_param.numpy(), data_cur_param.numpy(),  marker='o') \n",
    "            ax_list[i // n_col, i % n_col].set_title(param)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(plot_name)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "            # 예제 사용\n",
    "            # device 설정: CUDA 사용 가능한 경우 CUDA 사용, 그렇지 않으면 CPU 사용\n",
    "            #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            # CustomClass 객체 생성 예제\n",
    "            #simulation_sdss = CustomClass(root='/home/intern/SSD/intern/taejun/test', train=True, preprocess=True,quantization=1, device=device)\n",
    "\n",
    "            # 객체 생성 시, preprocess=True로 설정하여 데이터 전처리 및 저장이 이루어집니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드에 구현된거 하지만 잘 안된다 수정해서 해보자\n",
    "def variable_time_collate_fn(batch, args, device = device, data_type = \"train\", \n",
    "\tdata_min = None, data_max = None):\n",
    "\t\"\"\"\n",
    "\tExpects a batch of time series data in the form of (record_id, tt, vals, mask, labels) where\n",
    "\t\t- record_id is a patient id\n",
    "\t\t- tt is a 1-dimensional tensor containing T time values of observations.\n",
    "\t\t- vals is a (T, D) tensor containing observed values for D variables.\n",
    "\t\t- mask is a (T, D) tensor containing 1 where values were observed and 0 otherwise.\n",
    "\t\t- labels is a list of labels for the current patient, if labels are available. Otherwise None.\n",
    "\tReturns:\n",
    "\t\tcombined_tt: The union of all time observations.\n",
    "\t\tcombined_vals: (M, T, D) tensor containing the observed values.\n",
    "\t\tcombined_mask: (M, T, D) tensor containing 1 where values were observed and 0 otherwise.\n",
    "\t\"\"\"\n",
    "\tD = batch[0][2].shape[1]\n",
    "\tcombined_tt, inverse_indices = torch.unique(torch.cat([ex[1] for ex in batch]), sorted=True, return_inverse=True)\n",
    "\tcombined_tt = combined_tt.to(device)\n",
    "\n",
    "\toffset = 0\n",
    "\tcombined_vals = torch.zeros([len(batch), len(combined_tt), D]).to(device)\n",
    "\tcombined_mask = torch.zeros([len(batch), len(combined_tt), D]).to(device)\n",
    "\t\n",
    "\tcombined_labels = None\n",
    "\tN_labels = 1\n",
    "\n",
    "\tcombined_labels = torch.zeros(len(batch), N_labels) + torch.tensor(float('nan'))\n",
    "\tcombined_labels = combined_labels.to(device = device)\n",
    "\t\n",
    "\tfor b, (record_id, tt, vals, mask, labels) in enumerate(batch):\n",
    "\t\ttt = tt.to(device)\n",
    "\t\tvals = vals.to(device)\n",
    "\t\tmask = mask.to(device)\n",
    "\t\tif labels is not None:\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\tindices = inverse_indices[offset:offset + len(tt)]\n",
    "\t\toffset += len(tt)\n",
    "\n",
    "\t\tcombined_vals[b, indices] = vals\n",
    "\t\tcombined_mask[b, indices] = mask\n",
    "\n",
    "\t\tif labels is not None:\n",
    "\t\t\tcombined_labels[b] = labels\n",
    "\n",
    "\tcombined_vals, _, _ = utils.normalize_masked_data(combined_vals, combined_mask, \n",
    "\t  \tatt_min = data_min, att_max = data_max)\n",
    "\n",
    "\t# if torch.max(combined_tt) != 0.:\n",
    "\t# \tcombined_tt = combined_tt / torch.max(combined_tt)\n",
    "\t\n",
    "\tdata_dict = {\n",
    "\t\t\"data\": combined_vals, \n",
    "\t\t\"time_steps\": combined_tt,\n",
    "\t\t\"mask\": combined_mask,\n",
    "\t\t\"labels\": combined_labels}\n",
    "\t\n",
    "\tdata_dict = utils.split_and_subsample_batch(data_dict, args, data_type = data_type)\n",
    "\treturn data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_batch = next(iter(train_dataloader))\n",
    "\n",
    "# # 첫 번째 배치의 실제 내용을 출력하여 어떤 키가 있는지 확인\n",
    "# print(first_batch.keys())\n",
    "\n",
    "# # 첫 번째 배치의 구성요소들의 shape를 출력\n",
    "# print(\"observed_data:\", first_batch['observed_data'].shape)\n",
    "# print(\"observed_tp:\", first_batch['observed_tp'].shape)\n",
    "# print(\"data_to_predict:\", first_batch['data_to_predict'].shape)\n",
    "# print(\"tp_to_predict:\", first_batch['tp_to_predict'].shape)\n",
    "# print(\"observed_mask:\", first_batch['observed_mask'].shape)\n",
    "# print(\"mask_predicted_data\", first_batch['mask_predicted_data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_zeros = torch.sum(first_batch['observed_mask']== 0).item()  # 마스크에서 0의 개수\n",
    "# num_ones = torch.sum(first_batch['observed_mask']== 1).item()\n",
    "\n",
    "# print(num_zeros)\n",
    "# print(num_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataLoader에서 첫 번째 배치 데이터를 가져옴\n",
    "# batch_data = next(iter(train_dataloader))\n",
    "# print(batch_data.keys())\n",
    "# # 마스킹된 데이터 확인\n",
    "# mask = batch_data[\"mask\"]  # \"mask\" 키를 사용하여 마스크 텐서를 가져옴\n",
    "\n",
    "# # 마스크 텐서에서 0과 1의 개수를 세어서 출력\n",
    "# num_zeros = torch.sum(mask == 0).item()  # 마스크에서 0의 개수\n",
    "# num_ones = torch.sum(mask == 1).item()  # 마스크에서 1의 개수\n",
    "\n",
    "# print(f\"마스크에서 0의 개수: {num_zeros}\")\n",
    "# print(f\"마스크에서 1의 개수: {num_ones}\")\n",
    "\n",
    "# # 옵셔널: 마스킹된 데이터 시각화\n",
    "# # 데이터와 마스크를 시각화하는 코드를 추가할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:04<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset_obj = CustomClass(root='/home/intern/SSD/intern/taejun/test_normal_cut', train=True, preprocess=True,quantization=5,n_samples = min(800, args.n), device=device)\n",
    "\t\t# Use custom collate_fn to combine samples with arbitrary time observations.\n",
    "\t\t# Returns the dataset along with mask and time steps\n",
    "\n",
    "\n",
    "# Combine and shuffle samples from physionet Train and physionet Test\n",
    "# 전체 데이터셋을 직접 사용하여 데이터로더 생성\n",
    "total_dataset = train_dataset_obj[:len(train_dataset_obj)]\n",
    "\n",
    "# input_dim 및 기타 필요한 설정 계산\n",
    "n_samples = len(total_dataset)\n",
    "input_dim = total_dataset[0][2].size(-1)  # vals의 마지막 차원 크기로 input_dim 설정\n",
    "\n",
    "batch_size = min(min(len(train_dataset_obj), args.batch_size), args.n)\n",
    "data_min, data_max = get_data_min_max(total_dataset)\n",
    "\n",
    "# 동일한 데이터셋을 사용하여 train_dataloader와 test_dataloader 생성\n",
    "train_dataloader = DataLoader(total_dataset, batch_size=batch_size, shuffle=True, \n",
    "    collate_fn=lambda batch: variable_time_collate_fn(batch, args, device, data_type=\"train\",\n",
    "        data_min=data_min, data_max=data_max))\n",
    "test_dataloader = DataLoader(total_dataset, batch_size=batch_size, shuffle=False, \n",
    "    collate_fn=lambda batch: variable_time_collate_fn(batch, args, device, data_type=\"test\",\n",
    "        data_min=data_min, data_max=data_max))\n",
    "\n",
    "attr_names = train_dataset_obj.params\n",
    "data_objects = {\n",
    "    \"dataset_obj\": train_dataset_obj,\n",
    "    \"train_dataloader\": utils.inf_generator(train_dataloader),\n",
    "    \"test_dataloader\": utils.inf_generator(test_dataloader),\n",
    "    \"input_dim\": input_dim,\n",
    "    \"n_train_batches\": len(train_dataloader),\n",
    "    \"n_test_batches\": len(test_dataloader),\n",
    "    \"attr\": attr_names,  # optional\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # `train_dataloader`에서 첫 번째 배치를 가져와서 형태와 내용을 확인합니다.\n",
    "# print(\"Train DataLoader:\")\n",
    "# for i, batch in enumerate(test_dataloader):\n",
    "#     print(f\"Batch {i}:\")\n",
    "#     print(\"observed_data.shape:\", batch['observed_data'].shape)\n",
    "#     print(\"observed_data:\", batch['observed_data'])\n",
    "#     # 여기에서 필요한 다른 키들도 확인할 수 있습니다.\n",
    "#     # 예를\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the directory where you want to save the file\n",
    "directory = \"experiments\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    # If the directory does not exist, create it\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling dataset of 24 training examples\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/usr/SSD/intern/taejun/latent_ode/taejun_sim_\n",
      "/home/intern/anaconda3/envs/taejun/lib/python3.8/site-packages/ipykernel_launcher.py --f=/home/intern/.local/share/jupyter/runtime/kernel-v2-1761594MK9kKD4dS0pf.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0003 [Test seq (cond on sampled tp)] | Loss 844.631714 | Likelihood -847.925171 | KL fp 1.1515 | FP STD 0.5134|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 903.9334716796875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.1703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0006 [Test seq (cond on sampled tp)] | Loss 635.607422 | Likelihood -638.575256 | KL fp 0.9905 | FP STD 0.5079|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 727.5928955078125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.1285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0009 [Test seq (cond on sampled tp)] | Loss 370.913818 | Likelihood -374.833923 | KL fp 0.9402 | FP STD 0.5773|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 481.4003601074219\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0012 [Test seq (cond on sampled tp)] | Loss 417.752563 | Likelihood -422.307343 | KL fp 0.8585 | FP STD 0.7045|\n",
      "KL coef: 0.01990000000000003\n",
      "Train loss (one batch): 446.25067138671875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0015 [Test seq (cond on sampled tp)] | Loss 407.145691 | Likelihood -415.499756 | KL fp 1.1494 | FP STD 1.3302|\n",
      "KL coef: 0.04900995010000009\n",
      "Train loss (one batch): 469.3471984863281\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0018 [Test seq (cond on sampled tp)] | Loss 341.975891 | Likelihood -349.486572 | KL fp 1.1354 | FP STD 1.3621|\n",
      "KL coef: 0.07725530557207994\n",
      "Train loss (one batch): 386.44122314453125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0021 [Test seq (cond on sampled tp)] | Loss 336.592804 | Likelihood -345.539368 | KL fp 1.1714 | FP STD 1.3736|\n",
      "KL coef: 0.10466174574128362\n",
      "Train loss (one batch): 388.1739807128906\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0024 [Test seq (cond on sampled tp)] | Loss 351.754944 | Likelihood -358.896240 | KL fp 1.2407 | FP STD 1.3764|\n",
      "KL coef: 0.13125418723102178\n",
      "Train loss (one batch): 398.3233642578125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0027 [Test seq (cond on sampled tp)] | Loss 336.610413 | Likelihood -345.735901 | KL fp 1.3069 | FP STD 1.3721|\n",
      "KL coef: 0.15705680661607324\n",
      "Train loss (one batch): 384.07574462890625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0030 [Test seq (cond on sampled tp)] | Loss 340.890930 | Likelihood -348.920563 | KL fp 1.3590 | FP STD 1.3638|\n",
      "KL coef: 0.18209306240276923\n",
      "Train loss (one batch): 389.0222473144531\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0033 [Test seq (cond on sampled tp)] | Loss 336.863159 | Likelihood -346.259552 | KL fp 1.3289 | FP STD 1.3553|\n",
      "KL coef: 0.20638571635634462\n",
      "Train loss (one batch): 383.48016357421875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0036 [Test seq (cond on sampled tp)] | Loss 338.442871 | Likelihood -346.342682 | KL fp 1.2653 | FP STD 1.3440|\n",
      "KL coef: 0.2299568541948449\n",
      "Train loss (one batch): 382.3265075683594\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0039 [Test seq (cond on sampled tp)] | Loss 336.743530 | Likelihood -345.869476 | KL fp 1.2137 | FP STD 1.3338|\n",
      "KL coef: 0.25282790566840385\n",
      "Train loss (one batch): 383.71527099609375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0042 [Test seq (cond on sampled tp)] | Loss 338.799866 | Likelihood -346.271606 | KL fp 1.1057 | FP STD 1.3163|\n",
      "KL coef: 0.2750196640421466\n",
      "Train loss (one batch): 381.8243408203125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0045 [Test seq (cond on sampled tp)] | Loss 335.998718 | Likelihood -344.732422 | KL fp 1.0825 | FP STD 1.3098|\n",
      "KL coef: 0.29655230500043084\n",
      "Train loss (one batch): 381.6473388671875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0048 [Test seq (cond on sampled tp)] | Loss 338.958008 | Likelihood -346.453857 | KL fp 1.0996 | FP STD 1.3185|\n",
      "KL coef: 0.31744540498961304\n",
      "Train loss (one batch): 382.0509338378906\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0051 [Test seq (cond on sampled tp)] | Loss 335.407227 | Likelihood -344.451630 | KL fp 1.1355 | FP STD 1.3320|\n",
      "KL coef: 0.33771795901601653\n",
      "Train loss (one batch): 381.75042724609375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0054 [Test seq (cond on sampled tp)] | Loss 338.054382 | Likelihood -345.817078 | KL fp 1.1669 | FP STD 1.3413|\n",
      "KL coef: 0.3573883979152819\n",
      "Train loss (one batch): 381.5753173828125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0057 [Test seq (cond on sampled tp)] | Loss 334.986938 | Likelihood -344.206390 | KL fp 1.1780 | FP STD 1.3458|\n",
      "KL coef: 0.37647460510880004\n",
      "Train loss (one batch): 381.7443542480469\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0060 [Test seq (cond on sampled tp)] | Loss 337.860443 | Likelihood -345.658691 | KL fp 1.1733 | FP STD 1.3478|\n",
      "KL coef: 0.39499393286246365\n",
      "Train loss (one batch): 381.62518310546875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0063 [Test seq (cond on sampled tp)] | Loss 334.646454 | Likelihood -343.858368 | KL fp 1.1645 | FP STD 1.3488|\n",
      "KL coef: 0.41296321806251557\n",
      "Train loss (one batch): 381.4039001464844\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0066 [Test seq (cond on sampled tp)] | Loss 337.700806 | Likelihood -345.451263 | KL fp 1.1602 | FP STD 1.3503|\n",
      "KL coef: 0.4303987975228408\n",
      "Train loss (one batch): 381.3919372558594\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0069 [Test seq (cond on sampled tp)] | Loss 334.372620 | Likelihood -343.599670 | KL fp 1.1641 | FP STD 1.3537|\n",
      "KL coef: 0.4473165228376149\n",
      "Train loss (one batch): 381.31219482421875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0072 [Test seq (cond on sampled tp)] | Loss 337.371216 | Likelihood -345.160889 | KL fp 1.1723 | FP STD 1.3580|\n",
      "KL coef: 0.463731774792815\n",
      "Train loss (one batch): 381.19927978515625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0075 [Test seq (cond on sampled tp)] | Loss 333.990479 | Likelihood -343.301758 | KL fp 1.1789 | FP STD 1.3618|\n",
      "KL coef: 0.4796594773496936\n",
      "Train loss (one batch): 381.17254638671875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0078 [Test seq (cond on sampled tp)] | Loss 337.109283 | Likelihood -344.927002 | KL fp 1.1799 | FP STD 1.3644|\n",
      "KL coef: 0.49511411121293036\n",
      "Train loss (one batch): 381.0914306640625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0081 [Test seq (cond on sampled tp)] | Loss 333.641479 | Likelihood -342.990967 | KL fp 1.1798 | FP STD 1.3668|\n",
      "KL coef: 0.510109726995795\n",
      "Train loss (one batch): 380.9811096191406\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0084 [Test seq (cond on sampled tp)] | Loss 336.845520 | Likelihood -344.677612 | KL fp 1.1830 | FP STD 1.3699|\n",
      "KL coef: 0.524659957994293\n",
      "Train loss (one batch): 380.92218017578125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0087 [Test seq (cond on sampled tp)] | Loss 333.276672 | Likelihood -342.684845 | KL fp 1.1847 | FP STD 1.3727|\n",
      "KL coef: 0.5387780325819045\n",
      "Train loss (one batch): 380.8394775390625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0090 [Test seq (cond on sampled tp)] | Loss 336.559448 | Likelihood -344.414673 | KL fp 1.1871 | FP STD 1.3756|\n",
      "KL coef: 0.5524767862361895\n",
      "Train loss (one batch): 380.7532958984375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0093 [Test seq (cond on sampled tp)] | Loss 332.895569 | Likelihood -342.368164 | KL fp 1.1874 | FP STD 1.3781|\n",
      "KL coef: 0.5657686732081884\n",
      "Train loss (one batch): 380.6755676269531\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0096 [Test seq (cond on sampled tp)] | Loss 336.259827 | Likelihood -344.149841 | KL fp 1.1924 | FP STD 1.3816|\n",
      "KL coef: 0.578665777845232\n",
      "Train loss (one batch): 380.58880615234375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0099 [Test seq (cond on sampled tp)] | Loss 333.792786 | Likelihood -342.148773 | KL fp 1.0701 | FP STD 1.3153|\n",
      "KL coef: 0.5911798255774507\n",
      "Train loss (one batch): 380.4110107421875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0102 [Test seq (cond on sampled tp)] | Loss 336.481445 | Likelihood -344.147339 | KL fp 1.0088 | FP STD 1.2051|\n",
      "KL coef: 0.6033221935779749\n",
      "Train loss (one batch): 380.9286193847656\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0105 [Test seq (cond on sampled tp)] | Loss 334.134338 | Likelihood -341.140503 | KL fp 0.9996 | FP STD 1.1767|\n",
      "KL coef: 0.6151039211065155\n",
      "Train loss (one batch): 380.880859375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0108 [Test seq (cond on sampled tp)] | Loss 336.006653 | Likelihood -343.750214 | KL fp 1.0064 | FP STD 1.1908|\n",
      "KL coef: 0.6265357195457308\n",
      "Train loss (one batch): 380.6545715332031\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0111 [Test seq (cond on sampled tp)] | Loss 333.611542 | Likelihood -340.840210 | KL fp 1.0208 | FP STD 1.2202|\n",
      "KL coef: 0.6376279821395031\n",
      "Train loss (one batch): 380.3255310058594\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0114 [Test seq (cond on sampled tp)] | Loss 335.654480 | Likelihood -343.510986 | KL fp 1.0365 | FP STD 1.2493|\n",
      "KL coef: 0.6483907934419777\n",
      "Train loss (one batch): 379.9598693847656\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0117 [Test seq (cond on sampled tp)] | Loss 332.946106 | Likelihood -340.589172 | KL fp 1.0496 | FP STD 1.2715|\n",
      "KL coef: 0.6588339384859576\n",
      "Train loss (one batch): 379.5506286621094\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0120 [Test seq (cond on sampled tp)] | Loss 335.311218 | Likelihood -343.155121 | KL fp 1.0595 | FP STD 1.2868|\n",
      "KL coef: 0.6689669116789861\n",
      "Train loss (one batch): 379.2080078125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0123 [Test seq (cond on sampled tp)] | Loss 332.311676 | Likelihood -340.208282 | KL fp 1.0669 | FP STD 1.2968|\n",
      "KL coef: 0.6787989254352086\n",
      "Train loss (one batch): 378.9063720703125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0126 [Test seq (cond on sampled tp)] | Loss 334.929565 | Likelihood -342.770081 | KL fp 1.0719 | FP STD 1.3020|\n",
      "KL coef: 0.6883389185508575\n",
      "Train loss (one batch): 378.63641357421875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0129 [Test seq (cond on sampled tp)] | Loss 331.848755 | Likelihood -339.776367 | KL fp 1.0748 | FP STD 1.3026|\n",
      "KL coef: 0.6975955643309785\n",
      "Train loss (one batch): 378.38970947265625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0132 [Test seq (cond on sampled tp)] | Loss 334.498474 | Likelihood -342.388245 | KL fp 1.0761 | FP STD 1.2992|\n",
      "KL coef: 0.7065772784747841\n",
      "Train loss (one batch): 378.1416320800781\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0135 [Test seq (cond on sampled tp)] | Loss 331.548767 | Likelihood -339.318756 | KL fp 1.0765 | FP STD 1.2929|\n",
      "KL coef: 0.7152922267268045\n",
      "Train loss (one batch): 377.89910888671875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0138 [Test seq (cond on sampled tp)] | Loss 334.025085 | Likelihood -342.006195 | KL fp 1.0767 | FP STD 1.2847|\n",
      "KL coef: 0.7237483323007917\n",
      "Train loss (one batch): 377.65130615234375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0141 [Test seq (cond on sampled tp)] | Loss 331.267426 | Likelihood -338.848022 | KL fp 1.0777 | FP STD 1.2774|\n",
      "KL coef: 0.7319532830831259\n",
      "Train loss (one batch): 377.388427734375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0144 [Test seq (cond on sampled tp)] | Loss 333.562500 | Likelihood -341.639160 | KL fp 1.0813 | FP STD 1.2798|\n",
      "KL coef: 0.739914538622274\n",
      "Train loss (one batch): 377.09185791015625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0147 [Test seq (cond on sampled tp)] | Loss 330.772552 | Likelihood -338.433228 | KL fp 1.0856 | FP STD 1.2867|\n",
      "KL coef: 0.7476393369106538\n",
      "Train loss (one batch): 376.76177978515625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0150 [Test seq (cond on sampled tp)] | Loss 333.128296 | Likelihood -341.303345 | KL fp 1.0874 | FP STD 1.2854|\n",
      "KL coef: 0.7551347009650705\n",
      "Train loss (one batch): 376.44183349609375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0153 [Test seq (cond on sampled tp)] | Loss 330.360291 | Likelihood -338.003784 | KL fp 1.0889 | FP STD 1.2856|\n",
      "KL coef: 0.762407445211707\n",
      "Train loss (one batch): 376.1205749511719\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0156 [Test seq (cond on sampled tp)] | Loss 332.670349 | Likelihood -340.982941 | KL fp 1.0896 | FP STD 1.2846|\n",
      "KL coef: 0.769464181681474\n",
      "Train loss (one batch): 375.7864074707031\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0159 [Test seq (cond on sampled tp)] | Loss 329.966553 | Likelihood -337.578613 | KL fp 1.0892 | FP STD 1.2818|\n",
      "KL coef: 0.7763113260213526\n",
      "Train loss (one batch): 375.44866943359375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0162 [Test seq (cond on sampled tp)] | Loss 332.212463 | Likelihood -340.677734 | KL fp 1.0884 | FP STD 1.2787|\n",
      "KL coef: 0.7829551033271924\n",
      "Train loss (one batch): 375.1028137207031\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0165 [Test seq (cond on sampled tp)] | Loss 329.608582 | Likelihood -337.166565 | KL fp 1.0870 | FP STD 1.2738|\n",
      "KL coef: 0.7894015538032715\n",
      "Train loss (one batch): 374.75244140625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0168 [Test seq (cond on sampled tp)] | Loss 331.779083 | Likelihood -340.394592 | KL fp 1.0861 | FP STD 1.2703|\n",
      "KL coef: 0.7956565382537605\n",
      "Train loss (one batch): 374.3973693847656\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0171 [Test seq (cond on sampled tp)] | Loss 329.270233 | Likelihood -336.798492 | KL fp 1.0860 | FP STD 1.2675|\n",
      "KL coef: 0.8017257434110856\n",
      "Train loss (one batch): 374.0306396484375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0174 [Test seq (cond on sampled tp)] | Loss 331.398987 | Likelihood -340.158691 | KL fp 1.0868 | FP STD 1.2655|\n",
      "KL coef: 0.8076146871060329\n",
      "Train loss (one batch): 373.6671142578125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0177 [Test seq (cond on sampled tp)] | Loss 328.965698 | Likelihood -336.494446 | KL fp 1.0886 | FP STD 1.2647|\n",
      "KL coef: 0.8133287232842966\n",
      "Train loss (one batch): 373.2960205078125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0180 [Test seq (cond on sampled tp)] | Loss 331.081787 | Likelihood -339.980927 | KL fp 1.0913 | FP STD 1.2649|\n",
      "KL coef: 0.8188730468740297\n",
      "Train loss (one batch): 372.933349609375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0183 [Test seq (cond on sampled tp)] | Loss 328.698059 | Likelihood -336.253540 | KL fp 1.0942 | FP STD 1.2648|\n",
      "KL coef: 0.8242526985088242\n",
      "Train loss (one batch): 372.5717468261719\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0186 [Test seq (cond on sampled tp)] | Loss 330.814972 | Likelihood -339.851074 | KL fp 1.0975 | FP STD 1.2651|\n",
      "KL coef: 0.8294725691104137\n",
      "Train loss (one batch): 372.22412109375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0189 [Test seq (cond on sampled tp)] | Loss 328.471130 | Likelihood -336.066223 | KL fp 1.1011 | FP STD 1.2658|\n",
      "KL coef: 0.8345374043352652\n",
      "Train loss (one batch): 371.8796691894531\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0192 [Test seq (cond on sampled tp)] | Loss 330.599792 | Likelihood -339.770477 | KL fp 1.1048 | FP STD 1.2664|\n",
      "KL coef: 0.8394518088891035\n",
      "Train loss (one batch): 371.5502014160156\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0195 [Test seq (cond on sampled tp)] | Loss 328.282654 | Likelihood -335.924072 | KL fp 1.1088 | FP STD 1.2671|\n",
      "KL coef: 0.8442202507132883\n",
      "Train loss (one batch): 371.2306823730469\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0198 [Test seq (cond on sampled tp)] | Loss 330.426086 | Likelihood -339.731354 | KL fp 1.1133 | FP STD 1.2686|\n",
      "KL coef: 0.8488470650468529\n",
      "Train loss (one batch): 370.91888427734375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0201 [Test seq (cond on sampled tp)] | Loss 328.134827 | Likelihood -335.840576 | KL fp 1.1174 | FP STD 1.2687|\n",
      "KL coef: 0.8533364583678963\n",
      "Train loss (one batch): 370.6153869628906\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0204 [Test seq (cond on sampled tp)] | Loss 330.287048 | Likelihood -339.730774 | KL fp 1.1238 | FP STD 1.2732|\n",
      "KL coef: 0.8576925122179114\n",
      "Train loss (one batch): 370.33160400390625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0207 [Test seq (cond on sampled tp)] | Loss 328.092712 | Likelihood -335.778839 | KL fp 1.1212 | FP STD 1.2603|\n",
      "KL coef: 0.8619191869125272\n",
      "Train loss (one batch): 370.0100402832031\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0210 [Test seq (cond on sampled tp)] | Loss 330.155975 | Likelihood -340.000824 | KL fp 1.1644 | FP STD 1.3339|\n",
      "KL coef: 0.8660203251420383\n",
      "Train loss (one batch): 370.0329895019531\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0213 [Test seq (cond on sampled tp)] | Loss 327.204041 | Likelihood -336.364624 | KL fp 1.1963 | FP STD 1.3863|\n",
      "KL coef: 0.8699996554649946\n",
      "Train loss (one batch): 370.35400390625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0216 [Test seq (cond on sampled tp)] | Loss 331.247314 | Likelihood -340.739197 | KL fp 1.1896 | FP STD 1.3649|\n",
      "KL coef: 0.8738607956980289\n",
      "Train loss (one batch): 369.98724365234375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0219 [Test seq (cond on sampled tp)] | Loss 327.633728 | Likelihood -335.554382 | KL fp 1.1484 | FP STD 1.2867|\n",
      "KL coef: 0.8776072562050017\n",
      "Train loss (one batch): 369.4851989746094\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0222 [Test seq (cond on sampled tp)] | Loss 329.771179 | Likelihood -339.183014 | KL fp 1.0990 | FP STD 1.1734|\n",
      "KL coef: 0.8812424430884569\n",
      "Train loss (one batch): 369.66094970703125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0225 [Test seq (cond on sampled tp)] | Loss 327.351257 | Likelihood -334.163696 | KL fp 1.1001 | FP STD 1.0923|\n",
      "KL coef: 0.8847696612862866\n",
      "Train loss (one batch): 370.9407043457031\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0228 [Test seq (cond on sampled tp)] | Loss 329.488037 | Likelihood -339.531403 | KL fp 1.1328 | FP STD 1.2235|\n",
      "KL coef: 0.8881921175764227\n",
      "Train loss (one batch): 369.181884765625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0231 [Test seq (cond on sampled tp)] | Loss 327.952759 | Likelihood -335.786499 | KL fp 1.1539 | FP STD 1.2603|\n",
      "KL coef: 0.8915129234922854\n",
      "Train loss (one batch): 368.6625671386719\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0234 [Test seq (cond on sampled tp)] | Loss 329.694641 | Likelihood -339.579132 | KL fp 1.1365 | FP STD 1.1997|\n",
      "KL coef: 0.894735098151641\n",
      "Train loss (one batch): 368.61175537109375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0237 [Test seq (cond on sampled tp)] | Loss 327.733887 | Likelihood -334.927002 | KL fp 1.1414 | FP STD 1.1920|\n",
      "KL coef: 0.897861571001439\n",
      "Train loss (one batch): 368.6969909667969\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0240 [Test seq (cond on sampled tp)] | Loss 329.660217 | Likelihood -339.845154 | KL fp 1.1536 | FP STD 1.2321|\n",
      "KL coef: 0.9008951844811254\n",
      "Train loss (one batch): 368.0889587402344\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0243 [Test seq (cond on sampled tp)] | Loss 328.138794 | Likelihood -335.594208 | KL fp 1.1515 | FP STD 1.2132|\n",
      "KL coef: 0.9038386966068515\n",
      "Train loss (one batch): 367.85821533203125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0246 [Test seq (cond on sampled tp)] | Loss 329.071838 | Likelihood -337.790314 | KL fp 1.0898 | FP STD 1.0323|\n",
      "KL coef: 0.9066947834789314\n",
      "Train loss (one batch): 371.27044677734375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  5132\n",
      "no_zero_count 개수:  2308\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0249 [Test seq (cond on sampled tp)] | Loss 327.785522 | Likelihood -335.102295 | KL fp 1.1831 | FP STD 1.2121|\n",
      "KL coef: 0.9094660417148236\n",
      "Train loss (one batch): 367.7970275878906\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n",
      "Computing loss... 1\n",
      "zero_count 개수:  2168\n",
      "no_zero_count 개수:  1136\n",
      "shape torch.Size([10, 1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 63174\n",
      "Epoch 0252 [Test seq (cond on sampled tp)] | Loss 330.270966 | Likelihood -340.548340 | KL fp 1.1824 | FP STD 1.2352|\n",
      "KL coef: 0.9121549908098516\n",
      "Train loss (one batch): 367.4559326171875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 162\u001b[0m\n\u001b[1;32m    160\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_next_batch(data_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# print(batch_dict)\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m train_res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_all_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkl_coef\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkl_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m train_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    164\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/media/usr/SSD/intern/taejun/latent_ode/lib/base_models.py:256\u001b[0m, in \u001b[0;36mVAE_Baseline.compute_all_losses\u001b[0;34m(self, batch_dict, n_traj_samples, kl_coef)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_all_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_dict, n_traj_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m):\n\u001b[1;32m    254\u001b[0m \t\u001b[38;5;66;03m# Condition on subsampled points\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \t\u001b[38;5;66;03m# Make predictions for all the points\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m \tpred_y, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtp_to_predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_tp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \t\u001b[38;5;66;03m#print(\"get_reconstruction done -- computing likelihood\")\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \tfp_mu, fp_std, fp_enc \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_point\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/media/usr/SSD/intern/taejun/latent_ode/lib/latent_ode.py:88\u001b[0m, in \u001b[0;36mLatentODE.get_reconstruction\u001b[0;34m(self, time_steps_to_predict, truth, truth_time_steps, mask, n_traj_samples, run_backwards, mode)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(first_point_enc_aug)\u001b[38;5;241m.\u001b[39many())\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Shape of sol_y [n_traj_samples, n_samples, n_timepoints, n_latents]\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m sol_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffeq_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_point_enc_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps_to_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poisson_proc:\n\u001b[1;32m     91\u001b[0m \tsol_y, log_lambda_y, int_lambda, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq_solver\u001b[38;5;241m.\u001b[39mode_func\u001b[38;5;241m.\u001b[39mextract_poisson_rate(sol_y)\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/usr/SSD/intern/taejun/latent_ode/lib/diffeq_solver.py:40\u001b[0m, in \u001b[0;36mDiffeqSolver.forward\u001b[0;34m(self, first_point, time_steps_to_predict, backwards)\u001b[0m\n\u001b[1;32m     37\u001b[0m n_traj_samples, n_traj \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m n_dims \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modeint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modeint_atol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m pred_y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mmean(pred_y[:, :, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;241m-\u001b[39m first_point) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/anaconda3/envs/taejun/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py:68\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     66\u001b[0m k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f0, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (alpha_i, beta_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tableau\u001b[38;5;241m.\u001b[39malpha, tableau\u001b[38;5;241m.\u001b[39mbeta)):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alpha_i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.\u001b[39m:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;66;03m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m         ti \u001b[38;5;241m=\u001b[39m t1\n\u001b[1;32m     71\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mPREV\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\ttorch.manual_seed(args.random_seed)\n",
    "\tnp.random.seed(args.random_seed)\n",
    "\n",
    "\texperimentID = args.load\n",
    "\tif experimentID is None:\n",
    "\t\t# Make a new experiment ID\n",
    "\t\texperimentID = int(SystemRandom().random()*100000)\n",
    "\tckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
    "\n",
    "\tstart = time.time()\n",
    "\tprint(\"Sampling dataset of {} training examples\".format(args.n))\n",
    "\t\n",
    "\tinput_command = sys.argv\n",
    "\tind = [i for i in range(len(input_command)) if input_command[i] == \"--load\"]\n",
    "\tif len(ind) == 1:\n",
    "\t\tind = ind[0]\n",
    "\t\tinput_command = input_command[:ind] + input_command[(ind+2):]\n",
    "\tinput_command = \" \".join(input_command)\n",
    "\n",
    "\tutils.makedirs(\"results/\")\n",
    "\n",
    "\t##################################################################\n",
    "\tdata_obj = data_objects\n",
    "\tinput_dim = data_obj[\"input_dim\"]\n",
    "\n",
    "\tclassif_per_tp = False\n",
    "\tif (\"classif_per_tp\" in data_obj):\n",
    "\t\t# do classification per time point rather than on a time series as a whole\n",
    "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
    "\n",
    "\tif args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
    "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
    "\n",
    "\tn_labels = 1\n",
    "\tif args.classif:\n",
    "\t\tif (\"n_labels\" in data_obj):\n",
    "\t\t\tn_labels = data_obj[\"n_labels\"]\n",
    "\t\telse:\n",
    "\t\t\traise Exception(\"Please provide number of labels for classification task\")\n",
    "\n",
    "\t##################################################################\n",
    "\t# Create the model\n",
    "\tobsrv_std = 0.01\n",
    "\tobsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
    "\tz0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))\n",
    "\n",
    "\tif args.rnn_vae:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
    "\n",
    "\t\t# Create RNN-VAE model\n",
    "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
    "\t\t\tdevice = device, \n",
    "\t\t\trec_dims = args.rec_dims, \n",
    "\t\t\tconcat_mask = True, \n",
    "\t\t\tobsrv_std = obsrv_std,\n",
    "\t\t\tz0_prior = z0_prior,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "\t\t\n",
    "\telif args.classic_rnn:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
    "\t\t# Create RNN model\n",
    "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "\t\t\n",
    "\telif args.ode_rnn:\n",
    "\t\t# Create ODE-GRU model\n",
    "\t\tn_ode_gru_dims = args.latents\n",
    "\t\t\t\t\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
    "\n",
    "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
    "\n",
    "\t\trec_ode_func = ODEFunc(\n",
    "\t\t\tinput_dim = input_dim, \n",
    "\t\t\tlatent_dim = n_ode_gru_dims,\n",
    "\t\t\tode_func_net = ode_func_net,\n",
    "\t\t\tdevice = device).to(device)\n",
    "\n",
    "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
    "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\t\n",
    "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
    "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "\telif args.latent_ode:\n",
    "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels)\n",
    "\telse:\n",
    "\t\traise Exception(\"Model not specified\")\n",
    "\n",
    "\t##################################################################\n",
    "\n",
    "\tif args.viz:\n",
    "\t\tviz = Visualizations(device)\n",
    "\n",
    "\t##################################################################\n",
    "\t\n",
    "\t#Load checkpoint and evaluate the model\n",
    "\tif args.load is not None:\n",
    "\t\tutils.get_ckpt_model(ckpt_path, model, device)\n",
    "\t\texit()\n",
    "\n",
    "\t##################################################################\n",
    "\t# Training\n",
    "\n",
    "\tlog_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
    "\tif not os.path.exists(\"logs/\"):\n",
    "\t\tutils.makedirs(\"logs/\")\n",
    "\tlogger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(file_name))\n",
    "\tlogger.info(input_command)\n",
    "\n",
    "\toptimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
    "\n",
    "\tnum_batches = data_obj[\"n_train_batches\"]\n",
    "\n",
    "\tfor itr in range(1, num_batches * (args.niters + 1)):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tutils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
    "\n",
    "\t\twait_until_kl_inc = 10\n",
    "\t\tif itr // num_batches < wait_until_kl_inc:\n",
    "\t\t\tkl_coef = 0.\n",
    "\t\telse:\n",
    "\t\t\tkl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
    "\n",
    "\t\tbatch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
    "\t\t# print(batch_dict)\n",
    "\t\ttrain_res = model.compute_all_losses(batch_dict, n_traj_samples = 10, kl_coef = kl_coef)\n",
    "\t\ttrain_res[\"loss\"].backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tn_iters_to_viz = 3\n",
    "\t\tif itr % (n_iters_to_viz * num_batches) == 0:\n",
    "\t\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\t\ttest_res = compute_loss_all_batches(model, \n",
    "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
    "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
    "\t\t\t\t\texperimentID = experimentID,\n",
    "\t\t\t\t\tdevice = device,\n",
    "\t\t\t\t\tn_traj_samples = 5, kl_coef = kl_coef)\n",
    "\n",
    "\t\t\t\tmessage = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
    "\t\t\t\t\titr//num_batches, \n",
    "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
    "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
    "\t\t\t\tsample_test = utils.get_next_batch(data_obj[\"test_dataloader\"])\n",
    "\t\t\t\tno_zero_count = torch.sum(sample_test['observed_data']!= 0).item()\n",
    "\t\t\t\tzero_count = torch.sum(sample_test['observed_data'] == 0).item()\n",
    "\t\t\t\tprint(\"zero_count 개수: \",zero_count)\n",
    "\t\t\t\tprint(\"no_zero_count 개수: \",no_zero_count)\n",
    "\t\t\t\tplot_name = \"test_2024_02_15_4_{:04d}\".format(itr//num_batches)\n",
    "\t\t\t\tviz.draw_all_plots_one_dim(sample_test ,model.to(device), plot_name=plot_name, save = True)\n",
    "\t\t\t\t\n",
    "\t\t \t\n",
    "\t\t\t\tlogger.info(\"Experiment \" + str(experimentID))\n",
    "\t\t\t\tlogger.info(message)\n",
    "\t\t\t\tlogger.info(\"KL coef: {}\".format(kl_coef))\n",
    "\t\t\t\tlogger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
    "\t\t\t\tlogger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\tif \"mse\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traj_from_prior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtraj_from_prior\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traj_from_prior' is not defined"
     ]
    }
   ],
   "source": [
    "print(traj_from_prior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 523, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict['observed_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object inf_generator at 0x7fcfd36ec190>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj[\"test_dataloader\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taejun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
